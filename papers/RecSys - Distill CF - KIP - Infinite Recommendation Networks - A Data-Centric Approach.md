# DISTILL-CF/KIP-RecSys - Infinite Recommendation Networks: A Data-Centric Approach

- [DISTILL-CF/KIP-RecSys - Infinite Recommendation Networks: A Data-Centric Approach](#distill-cfkip-recsys---infinite-recommendation-networks-a-data-centric-approach)
- [What did the authors tried to accomplished?](#what-did-the-authors-tried-to-accomplished)
- [Key elements of the approach](#key-elements-of-the-approach)
- [Results (Good or Bad)](#results-good-or-bad)
- [Other references to follow](#other-references-to-follow)
- [Code Analysis](#code-analysis)
- [TODO](#todo)
- [More](#more)

**Keywords**:
- TODO

**TLDR**
- Synethic small, representative **collobrative filtering (CF)**

- TODO
- contribution

**openreview**

- Other's summary

**Takeaway**

(what can be used in my part)


# What did the authors tried to accomplished?

**Main idea.**  TODO  
**Motivation.** TODO  
**Previous problems.** TODO  


# Key elements of the approach

**Steps**.  
**Presudo code.**   

(from method)

- ∞-AE scalaility problem
  - DISTILL-CF
  - leveraging a simple observation from support vector machines: not all datapoints (users in our case) are important for model learning

**Motivation section**.
- DISTILL-CF distill data which serves as input for the ∞-AE

# Results (Good or Bad)

(from conclusion)

# Other references to follow

* poster - https://nips.cc/media/PosterPDFs/NeurIPS%202022/7d92c08873b4979b544e7fb64fdb1c6c.png?t=1667435206.2723856
* slides - https://www.noveens.com/data/neurips_22_slides.pdf

**More explanation**

**More papers**

# Code Analysis

(main file logic and key implementation details)

# TODO

1. summary
2. author / others explanation video / article
3. openreview
4. code

# More

Template based on:
- Stanford CS230: Deep Learning | Autumn 2018 | Lecture 8 - Career Advice / Reading Research Papers

**To understand better**
- openreview
- author's conference presentation
- youtube videos from other uni student
- reddit discussion
- twitter discussion